# Can LLMs write like Humans? 

## An Analysis of Linguistics Features in LLM Generations with Machine Learning
Marissa Todesco, Tianqi Zhang

### Project Description

In recent years, advancements in language modeling has led to the production of Large Language Models (LLMs), neural networks capable of producing grammatical, human-like text. 
Their language capabilities are truly impressive, able to perform complex linguistic tasks (such as summarization and question answering<sup>1</sup> and even pass the Turing test<sup>2</sup>. 
Because of these capabilities, LLM-generated text has become commonplace in online spaces, academia, and beyond. 
Since 2023, there has been a significant increase in LLM-generated text in scientific articles<sup>3</sup> and in commonly-visited web pages, such as Wikipedia<sup>4, 5</sup>. 
This has significant societal and ethical implications. 
Since LLMs are able to produce massive volumes of text in relatively short amounts of time, they can be easily used to proliferate misinformation, fake social interactions online, and author false academic papers, producing fake results. 
Indeed, in commonly used online spaces such as X (formerly Twitter), this is already becoming a problem<sup>6, 7</sup>.

Luckily, many investigations into LLM-generated texts have revealed persisting systematic differences between LLM and human productions<sup>8, 9, 10</sup>.
Most of these differences stem from higher-level linguistic features that are not immediately noticable.
The understanding of these systematic differences is key to understanding not only how LLMs generate text, but also to working towards a way to distinguish them from humans.
In this project, we attempt to build an LLM detection tool, making use of simple and interpretable machine learning models (random forest classifier and logistic regression) to gain a deeper and more nuanced understanding of what distinguishes LLM text from human text.
Specifically, we take inspiration from the work of Reinhardt et. al.<sup>11</sup>, employing the 67 linguistic features proposed by Douglas Biber<sup>12</sup> to classify between LLM-generated and human-generated texts. 
We extend their work by focusing on more general LLM vs. Human differences rather than exploring differences between different models, as well as more analysis on feature importance and model selection.
From these analyses, we draw conclusions about LLMs and their linguistic patterns.

We explore the following research questions in this project:
1. **Do Biber features encode significant information about whether a text is generated by an LLM or written by a human?**
2. **Which features are the most important/contain the most information?**
3. **What conclusions can we draw about LLM vs. human generation of text?**

***
### Setup

### Data Overview

As we are replicating and extending the work of Reinhardt et. al., we use the [dataset they curated](https://huggingface.co/datasets/browndw/human-ai-parallel-corpus-biber) of linguistic features extracted from both human and LLM-generated text. 
This dataset contains over 66,000 texts, each characterized with the 67 linguistic features proposed by Douglas Biber. 
These features encode grammatical, semantic, and lexical features of the text, and were first proposed to automate the classification of text into different registers.
Thorough explanation of the features and examples can be found in [the supporting information for Reinhart et. al.](https://www.pnas.org/doi/10.1073/pnas.2422455122#supplementary-materials)

25% of this dataset are human texts, taken from six genres (academic, news, fiction, spoken word, blogs, and TV/movie scripts).
The other 75% are LLM-generated texts, from 6 different models, including GPT and Llama models.
LLMs were given chunks of human text from the same sources as listed above, then prompted to generate more text to make the texts comparable.
***
### Code Structure
Code for this project can be found in `human-ai-biber.ipynb`, along with embedded commentary, figures, and analysis.
***
### Conclusions

#### **Do Biber features encode significant information about whether a text is generated by an LLM or written by a human?**

(INSERT FIGURE: ROC CURVES)

Simple statistical models were able to accurately classify between LLM-generated and human-generated.
The best random forest and logistic regression models achieved 93.7% and 82% accuracy respectively on a hidden test set, both significantly higher than the naive baseline accuracy of 75%.
Thus, it is clear that the features do encode significant information, such that these relatively simple statistical models are successful.

#### **Which features are the most important/contain the most information?**

(INSERT FIGURE: FEATURE IMPORTANCE)

Interestingly, it seems that the signal for LLM-generated vs. human-generated is pretty evenly spread across the 67 different linguistic features. 
For both models, the most successful model as determined through cross-validation was the one that contained most or all of the features.
This was true even for performance on a hidden test set, suggesting that the performance gain was not due to overfitting on the train set.

Some of the most important features in the random forest model were present-participle clauses, proportion of amplifiers, type-token ratio, and proportion of "other" nouns (nouns other than pronouns, nominalizations of verbs, and gerunds).
These partially corroborate the results from Reinhart et. al., as they also found present-participle clauses and other nouns to be among the most important.
However, our work demonstrates that lexical diversity (type-token ratio) and word choice (amplifiers, other nouns) are also informative for detecting LLM generations.
This is important, as these features *can* be roughly approximated at a glance by a human.

#### **What conclusions can we draw about LLM vs. human generation of text?**

(INSERT FIGURE: CONFUSION MATRIX)

One interesting result was that both the random forest and logistic regression models performed worse on human-generated texts than LLM-generated texts. 
Human-written text was often misclassified as LLM-generated based on just the linguistic features alone.
In fact, the logistic regression model performed almost at random for human-generated texts.
This could be a symptom of the unbalanced dataset.
Since 75% of the data was LLM-generated, the models were given more LLM examples than human.
This may have led the models to learn the features and patterns of LLM-generated text, while lacking understanding of human patterns.
Another highly likely explanation is that humans simply have less predictable patterns than LLMs.
Human texts were written by many different authors across different genres, while the LLM data was generated from only 6 different models.
The increased variation from author-specific effects in human texts would easily explain the models' failure to learn human linguistic patterns.


***
### Discussion and Future Work

From our analysis, we have learned much about LLMs and their linguistic patterns. 
The largest differences between LLMs and humans seem to be closely tied to specific word choice and vocabulary. 
However, we determined that the 67 Biber features all contain a small amount of signal for classifying between human and LLM texts, further solidifying that differences are extremely difficult to detect and require a hollistic look and multiple linguistic patterns.

One possible direction for future work is more language-model-specific analysis. 
While we generalized to LLM vs. Human in this project, this level of thorough statistical model selection and feature importance analysis could be done for the task of classifying between language models.
This would reveal differences in patterns caused by training paradigms, fine-tuning, model architecture differences, etc.

Another possible direction is genre-specific patterns.
6 different genres were analyzed together for this project in order to produce more general analyses.
Further analysis could be done to determine patterns within each genre, potentially finding where LLMs are most similar to humans and where they are least similar.
Additionally, LLMs have been shown to be bad at "code switching", or changing their production patterns based on prompting to write in a different genre without further fine-tuning.
Genre-specific anaysis of patterns could investigate this.

Finally, one could use this work to build a functional tool for LLM detection.
This would be useful in settings such as education, where cheating with AI use is most prominent.
Academic journals could also detect unauthorized use of LLMs in submissions.
However, in our experiments, we found that human texts were often misclassified as LLM texts, which could have devastating consequences in both these scenarios.
Future work would have to eliminate this weakness before being viable as an actual tool.

### Acknowledgements

We would like to thank Dr. Lucy Lai for providing feedback and mentoring on this project. 
Her invaluable insights helped us create a more polished final product. 
We would also like to thank Reinhart et. al. for their paper, the springboard for this project. 
Their prior analyses and clean dataset made our work much easier and overall made the process smoother.

### Works Cited
1. [Emergent Abilities of Large Language Models](https://doi.org/10.48550/arXiv.2206.07682)(Wei et. al., Transactions on Machine Learning Research 2022)
2. [Large Language Models Pass the Turing Test](10.48550/arXiv.2503.23674.) (Cameron R. Jones and Benjamin K. Bergen, 2025)
3. [Mapping the Increasing Use of LLMs in Scientific Papers](https://openreview.net/forum?id=YX7QnhxESU) (Liang et. al., First Conference on Language Modeling 2024)
4. [The Rise of AI-Generated Content in Wikipedia](https://aclanthology.org/2024.wikinlp-1.12/) (Brooks et al., WikiNLP 2024)
5. [Delving into: the quantification of Ai-generated content on the internet (synthetic data)](https://arxiv.org/abs/2504.08755)(Spenneman, 2025)
6. [Stylometric Detection of AI-Generated Text in Twitter Timelines](https://arxiv.org/abs/2303.03697) (Kumarage et. al., 2023)
7. [TweepFake: about Detecting Deepfake Tweets](https://arxiv.org/abs/2008.00036) (Fagni et. al., 2020)
8. [Benchmarking Linguistic Diversity of Large Language Models](https://arxiv.org/abs/2412.10271) (Guo et al., 2024)
9. [What Comes Next? Evaluating Uncertainty in Neural Text Generators Against Human Production Variability](https://aclanthology.org/2023.emnlp-main.887/)(Giulianelli et al., EMNLP 2023)
10. [Contrasting Linguistic Patterns in Human and LLM-Generated News Text](https://link.springer.com/article/10.1007/s10462-024-10903-2)(Mu√±oz-Ortiz et al., Artificial Intelligence Review 2024)
11. [Do LLMs write like humans? Variation in grammatical and rhetorical styles](https://www.pnas.org/doi/10.1073/pnas.2422455122#supplementary-materials)(Reinhart et. al., Proceedings of the National Academy of Sciences of the United States of America 2025)
12. [Using Register-Diversified Corpora for General Language Studies](https://aclanthology.org/J93-2001/)(Biber, CL 1993)